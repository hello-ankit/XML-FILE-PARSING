{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Set the desired width for displaying the XML_File column\n",
    "desired_width = 1000  # Adjust this value as needed\n",
    "pd.set_option('display.max_colwidth', desired_width)\n",
    "\n",
    "# Define the directory path containing the XML files\n",
    "directory_path = Path(r'C:\\Users\\41015078\\Desktop\\New folder\\19008365_01032025_025549.XML')\n",
    "\n",
    "# Use glob.glob() to get a list of file paths that match the pattern\n",
    "xml_files = glob.glob(str(directory_path / '*.xml'))\n",
    "\n",
    "# List to hold the extracted data\n",
    "data_list = []\n",
    "\n",
    "# List of tags to check for\n",
    "tags_to_check = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D1251', 'D1300']\n",
    "\n",
    "# Iterate through each XML file\n",
    "for xml_file in xml_files:\n",
    "    # Parse XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract the value of METER for each G1 element and check for each tag\n",
    "    for G1 in root.iter('G1'):\n",
    "        # Dictionary to hold the extracted data for the current G1 element\n",
    "        temp_dict = {'METER': G1.text}\n",
    "        \n",
    "        # Check for each tag in the XML\n",
    "        for tag in tags_to_check:\n",
    "            if root.find(f\".//{tag}\") is not None:\n",
    "                temp_dict[tag] = 'yes'\n",
    "            else:\n",
    "                temp_dict[tag] = 'no'\n",
    "        \n",
    "        # Append the temporary dictionary to the list\n",
    "        data_list.append(temp_dict)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "data_frame = pd.DataFrame(data_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(data_frame)\n",
    "# data_frame.to_csv(r'C:\\Users\\Dell\\Desktop\\h\\tags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826002da-b921-4c2b-a4bb-a7aa595f166f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cb65e0d-abd1-41ee-925b-6f2016e531ca",
   "metadata": {},
   "source": [
    "### New Update Code Below for Bulk XML files-Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the desired width for displaying the XML_File column\n",
    "desired_width = 1000  # Adjust this value as needed\n",
    "pd.set_option('display.max_colwidth', desired_width)\n",
    "\n",
    "# Define the directory path containing the XML files\n",
    "directory_path = Path(r'C:\\Users\\41015078\\Desktop\\New folder')\n",
    "\n",
    "# Use glob.glob() to get a list of file paths that match the pattern\n",
    "xml_files = glob.glob(str(directory_path / '*.xml'))\n",
    "\n",
    "# List to hold the extracted data\n",
    "data_list = []\n",
    "faulty_xml = []\n",
    "\n",
    "# List of tags to check for\n",
    "tags_to_check = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D1251', 'D1300']\n",
    "\n",
    "\n",
    "# Iterate through each XML file\n",
    "for xml_file in tqdm(xml_files):\n",
    "        \n",
    "    try:\n",
    "\n",
    "        # Parse XML file\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extract the value of METER for each G1 element and check for each tag\n",
    "        for G1 in root.iter('G1'):\n",
    "            # Dictionary to hold the extracted data for the current G1 element\n",
    "            temp_dict = {'METER': G1.text}\n",
    "            \n",
    "            # Check for each tag in the XML\n",
    "            for tag in tags_to_check:\n",
    "                if root.find(f\".//{tag}\") is not None:\n",
    "                    temp_dict[tag] = 'yes'\n",
    "                else:\n",
    "                    temp_dict[tag] = 'no'\n",
    "            \n",
    "            # Append the temporary dictionary to the list\n",
    "            data_list.append(temp_dict)\n",
    "    except:\n",
    "        faulty_xml.append(xml_file)\n",
    "\n",
    "# After the loop, save the faulty XML files to a CSV\n",
    "faulty_xml_df = pd.DataFrame(faulty_xml, columns=['Faulty_XML_Files'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "faulty_xml_df.to_csv(r'C:\\Users\\41015078\\Desktop\\New folder\\faulty_xml_files.csv', index=False)\n",
    "\n",
    "print(f\"Faulty XML files have been saved to 'faulty_xml_files.csv'\")\n",
    "\n",
    "\n",
    "print(\"No. of Faulty xmls\")\n",
    "print(len(faulty_xml))\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "data_frame = pd.DataFrame(data_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(data_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcacef-de5a-4848-acc3-f3e42dd03b0d",
   "metadata": {},
   "source": [
    "Final XML Tags Parameter Status Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ded48e-4615-4282-9d70-bdc0bbf613fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XML processing with threading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████████████████████████████████████████████████████| 651/651 [01:07<00:00,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting results...\n",
      "\n",
      "Processing completed in 67.31 seconds\n",
      "Total files processed: 651\n",
      "Normal XML files: 651\n",
      "Faulty XML files: 0\n",
      "Total records extracted: 651\n",
      "\n",
      "Files have been saved:\n",
      "1. processed_xml_data.csv - Contains all extracted data\n",
      "2. normal_xml_files.csv - List of successfully processed XML files\n",
      "3. faulty_xml_files.csv - List of XML files that failed to process\n",
      "\n",
      "Final XML files processed data:\n",
      "      METER   D1   D2   D3   D4   D5  D6  D7   D8   D9  D10 D11 D1251 D1300\n",
      "0  17008336  yes  yes  yes  yes  yes  no  no  yes  yes  yes  no    no    no\n",
      "1  17012660  yes  yes  yes  yes  yes  no  no  yes  yes  yes  no    no    no\n",
      "2  17013571  yes  yes  yes  yes  yes  no  no  yes  yes  yes  no    no    no\n",
      "3  17010614  yes  yes  yes  yes  yes  no  no  yes  yes  yes  no    no    no\n",
      "4  17013184  yes  yes  yes  yes  yes  no  no  yes  yes  yes  no    no    no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm  # Changed back to regular tqdm\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "# Set the desired width for displaying the XML_File column\n",
    "desired_width = 1000  # Adjust this value as needed\n",
    "pd.set_option('display.max_colwidth', desired_width)\n",
    "\n",
    "\n",
    "# Define the directory path containing the XML files\n",
    "directory_path = Path(r'Y:\\FY2024_25\\FEB25\\EMD XML FILES\\1\\Completed')\n",
    "\n",
    "\n",
    "# Use glob.glob() to get a list of file paths that match the pattern\n",
    "xml_files = glob.glob(str(directory_path / '*.xml'))\n",
    "\n",
    "\n",
    "# List to hold the extracted data\n",
    "data_list = []\n",
    "faulty_xml = []\n",
    "normal_xml = []\n",
    "\n",
    "\n",
    "# List of tags to check for\n",
    "tags_to_check = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D1251', 'D1300']\n",
    "\n",
    "\n",
    "# Thread-safe queues for data collection\n",
    "data_queue = Queue()\n",
    "faulty_queue = Queue()\n",
    "normal_queue = Queue()\n",
    "\n",
    "\n",
    "def process_xml_file(xml_file):\n",
    "    try:\n",
    "        # Parse XML file\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extract the value of METER for each G1 element and check for each tag\n",
    "        for G1 in root.iter('G1'):\n",
    "            # Dictionary to hold the extracted data for the current G1 element\n",
    "            temp_dict = {'METER': G1.text}\n",
    "            \n",
    "            # Check for each tag in the XML\n",
    "            for tag in tags_to_check:\n",
    "                if root.find(f\".//{tag}\") is not None:\n",
    "                    temp_dict[tag] = 'yes'\n",
    "                else:\n",
    "                    temp_dict[tag] = 'no'\n",
    "            \n",
    "            # Put the data in the queue\n",
    "            data_queue.put(temp_dict)\n",
    "        \n",
    "        # If we get here, the file was processed successfully\n",
    "        normal_queue.put(xml_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If there's an error, add to faulty queue\n",
    "        faulty_queue.put(xml_file)\n",
    "        print(f\"Error processing {xml_file}: {str(e)}\")\n",
    "\n",
    "\n",
    "def process_files_with_threading():\n",
    "    # Create a thread pool\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Submit all files to the thread pool\n",
    "        futures = [executor.submit(process_xml_file, xml_file) for xml_file in xml_files]\n",
    "        \n",
    "        # Show progress bar\n",
    "        with tqdm(total=len(xml_files), desc=\"Processing XML files\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "def collect_results():\n",
    "    # Collect data from queues\n",
    "    while not data_queue.empty():\n",
    "        data_list.append(data_queue.get())\n",
    "    \n",
    "    while not faulty_queue.empty():\n",
    "        faulty_xml.append(faulty_queue.get())\n",
    "    \n",
    "    while not normal_queue.empty():\n",
    "        normal_xml.append(normal_queue.get())\n",
    "\n",
    "\n",
    "# Start processing\n",
    "print(\"Starting XML processing with threading...\")\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "process_files_with_threading()\n",
    "\n",
    "\n",
    "print(\"Collecting results...\")\n",
    "collect_results()\n",
    "\n",
    "\n",
    "# Save the faulty XML files to a CSV\n",
    "faulty_xml_df = pd.DataFrame(faulty_xml, columns=['Faulty_XML_Files'])\n",
    "faulty_xml_df.to_csv(r'C:\\Users\\41015078\\Desktop\\3Phase XML Tag Status FrontEnd\\faulty_xml_files.csv', index=False)\n",
    "\n",
    "\n",
    "# Save the normal XML files to a CSV\n",
    "normal_xml_df = pd.DataFrame(normal_xml, columns=['Normal_XML_Files'])\n",
    "normal_xml_df.to_csv(r'C:\\Users\\41015078\\Desktop\\3Phase XML Tag Status FrontEnd\\normal_xml_files.csv', index=False)\n",
    "\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "data_frame = pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "# Save the processed data to a CSV\n",
    "data_frame.to_csv(r'C:\\Users\\41015078\\Desktop\\3Phase XML Tag Status FrontEnd\\processed_xml_data.csv', index=False)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "\n",
    "print(f\"\\nProcessing completed in {processing_time:.2f} seconds\")\n",
    "print(f\"Total files processed: {len(xml_files)}\")\n",
    "print(f\"Normal XML files: {len(normal_xml)}\")\n",
    "print(f\"Faulty XML files: {len(faulty_xml)}\")\n",
    "print(f\"Total records extracted: {len(data_list)}\")\n",
    "\n",
    "\n",
    "print(\"\\nFiles have been saved:\")\n",
    "print(\"1. processed_xml_data.csv - Contains all extracted data\")\n",
    "print(\"2. normal_xml_files.csv - List of successfully processed XML files\")\n",
    "print(\"3. faulty_xml_files.csv - List of XML files that failed to process\")\n",
    "\n",
    "\n",
    "# Display the first few rows of the processed data\n",
    "print(\"\\nFinal XML files processed data:\")\n",
    "print(data_frame.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b2750-6216-4c2f-b048-e037a244e4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
